{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR: End-to-End Object Detection with Transformers\n",
    "\n",
    "- Paper: [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)\n",
    "- Official video: [DETR - End to end object detection with transformers (ECCV2020)](https://youtu.be/utxbUlo9CyY?si=cIHkqMDQj7rMrTCk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "<img src=\"notebook_images/detr_overall.png\" width=\"900\">\n",
    "<br></br>\n",
    "\n",
    "## Output Matching\n",
    "<img src=\"notebook_images/detr_output_matching.png\" width=\"900\">\n",
    "<br></br>\n",
    "\n",
    "## Architecture\n",
    "<img src=\"notebook_images/detr_architecture.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETRdemo(nn.Module):\n",
    "    \"\"\"\n",
    "    Demo DETR implementation.\n",
    "\n",
    "    Demo implementation of DETR in minimal number of lines, with the\n",
    "    following differences wrt DETR in the paper:\n",
    "    * learned positional encoding (instead of sine)\n",
    "    * positional encoding is passed at input (instead of attention)\n",
    "    * fc bbox predictor (instead of MLP)\n",
    "    The model achieves ~40 AP on COCO val5k and runs at ~28 FPS on Tesla V100.\n",
    "    Only batch size 1 supported.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, hidden_dim=256, nheads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # create ResNet-50 backbone\n",
    "        self.backbone = resnet50()\n",
    "        del self.backbone.fc\n",
    "\n",
    "        # create conversion layer\n",
    "        self.conv = nn.Conv2d(2048, hidden_dim, 1)\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads, one extra class for predicting non-empty slots\n",
    "        # note that in baseline DETR linear_bbox layer is 3-layer MLP\n",
    "        self.linear_class = nn.Linear(hidden_dim, num_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.query_pos = nn.Parameter(torch.rand(100, hidden_dim))\n",
    "\n",
    "        # spatial positional encodings\n",
    "        # note that in baseline DETR we use sine positional encodings\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # propagate inputs through ResNet-50 up to avg-pool layer\n",
    "        x = self.backbone.conv1(inputs)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(x)\n",
    "\n",
    "        # construct positional encodings\n",
    "        H, W = h.shape[-2:]\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "        # propagate through the transformer\n",
    "        h = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1),\n",
    "                             self.query_pos.unsqueeze(1)).transpose(0, 1)\n",
    "\n",
    "        # finally project transformer outputs to class labels and bounding boxes\n",
    "        return {'pred_logits': self.linear_class(h),\n",
    "                'pred_boxes': self.linear_bbox(h).sigmoid()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kpatel2s/anaconda3/envs/detr/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "detr = DETRdemo(num_classes=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type (var_name))                                           Input Shape          Output Shape         Param #              Trainable\n",
       "=================================================================================================================================================\n",
       "DETRdemo (DETRdemo)                                               [1, 3, 224, 224]     [1, 100, 4]          38,400               True\n",
       "├─ResNet (backbone)                                               --                   --                   --                   True\n",
       "│    └─Conv2d (conv1)                                             [1, 3, 224, 224]     [1, 64, 112, 112]    9,408                True\n",
       "│    └─BatchNorm2d (bn1)                                          [1, 64, 112, 112]    [1, 64, 112, 112]    128                  True\n",
       "│    └─ReLU (relu)                                                [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
       "│    └─MaxPool2d (maxpool)                                        [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
       "│    └─Sequential (layer1)                                        [1, 64, 56, 56]      [1, 256, 56, 56]     --                   True\n",
       "│    │    └─Bottleneck (0)                                        [1, 64, 56, 56]      [1, 256, 56, 56]     75,008               True\n",
       "│    │    └─Bottleneck (1)                                        [1, 256, 56, 56]     [1, 256, 56, 56]     70,400               True\n",
       "│    │    └─Bottleneck (2)                                        [1, 256, 56, 56]     [1, 256, 56, 56]     70,400               True\n",
       "│    └─Sequential (layer2)                                        [1, 256, 56, 56]     [1, 512, 28, 28]     --                   True\n",
       "│    │    └─Bottleneck (0)                                        [1, 256, 56, 56]     [1, 512, 28, 28]     379,392              True\n",
       "│    │    └─Bottleneck (1)                                        [1, 512, 28, 28]     [1, 512, 28, 28]     280,064              True\n",
       "│    │    └─Bottleneck (2)                                        [1, 512, 28, 28]     [1, 512, 28, 28]     280,064              True\n",
       "│    │    └─Bottleneck (3)                                        [1, 512, 28, 28]     [1, 512, 28, 28]     280,064              True\n",
       "│    └─Sequential (layer3)                                        [1, 512, 28, 28]     [1, 1024, 14, 14]    --                   True\n",
       "│    │    └─Bottleneck (0)                                        [1, 512, 28, 28]     [1, 1024, 14, 14]    1,512,448            True\n",
       "│    │    └─Bottleneck (1)                                        [1, 1024, 14, 14]    [1, 1024, 14, 14]    1,117,184            True\n",
       "│    │    └─Bottleneck (2)                                        [1, 1024, 14, 14]    [1, 1024, 14, 14]    1,117,184            True\n",
       "│    │    └─Bottleneck (3)                                        [1, 1024, 14, 14]    [1, 1024, 14, 14]    1,117,184            True\n",
       "│    │    └─Bottleneck (4)                                        [1, 1024, 14, 14]    [1, 1024, 14, 14]    1,117,184            True\n",
       "│    │    └─Bottleneck (5)                                        [1, 1024, 14, 14]    [1, 1024, 14, 14]    1,117,184            True\n",
       "│    └─Sequential (layer4)                                        [1, 1024, 14, 14]    [1, 2048, 7, 7]      --                   True\n",
       "│    │    └─Bottleneck (0)                                        [1, 1024, 14, 14]    [1, 2048, 7, 7]      6,039,552            True\n",
       "│    │    └─Bottleneck (1)                                        [1, 2048, 7, 7]      [1, 2048, 7, 7]      4,462,592            True\n",
       "│    │    └─Bottleneck (2)                                        [1, 2048, 7, 7]      [1, 2048, 7, 7]      4,462,592            True\n",
       "├─Conv2d (conv)                                                   [1, 2048, 7, 7]      [1, 256, 7, 7]       524,544              True\n",
       "├─Transformer (transformer)                                       [49, 1, 256]         [100, 1, 256]        --                   True\n",
       "│    └─TransformerEncoder (encoder)                               [49, 1, 256]         [49, 1, 256]         --                   True\n",
       "│    │    └─ModuleList (layers)                                   --                   --                   7,890,432            True\n",
       "│    │    └─LayerNorm (norm)                                      [49, 1, 256]         [49, 1, 256]         512                  True\n",
       "│    └─TransformerDecoder (decoder)                               [100, 1, 256]        [100, 1, 256]        --                   True\n",
       "│    │    └─ModuleList (layers)                                   --                   --                   9,472,512            True\n",
       "│    │    └─LayerNorm (norm)                                      [100, 1, 256]        [100, 1, 256]        512                  True\n",
       "├─Linear (linear_class)                                           [1, 100, 256]        [1, 100, 92]         23,644               True\n",
       "├─Linear (linear_bbox)                                            [1, 100, 256]        [1, 100, 4]          1,028                True\n",
       "=================================================================================================================================================\n",
       "Total params: 41,459,616\n",
       "Trainable params: 41,459,616\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.05\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 199.67\n",
       "Params size (MB): 146.74\n",
       "Estimated Total Size (MB): 347.01\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model=detr,\n",
    "        input_size=(1, 3, 224, 224), # (batch_size, channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
